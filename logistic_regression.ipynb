{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38bf018",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "- training data => linear regression function 도출 \n",
    "- linear regression의 output을 sigmoid의 input x로 주면 => P(C=t|x) = y^t*(1-y)^(1-t)를 구할 수 있고 => 이를 이용해 손실 함수(cross-entropy)를 도출\n",
    "- Cross-entropy를 minimize하는 W, b값 도출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a731d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multi_var_numerical_derivative import multi_var_numerical_derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9b049",
   "metadata": {},
   "source": [
    "#### single variable logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb3e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0]\n",
      " [ 4  0]\n",
      " [ 6  0]\n",
      " [ 8  0]\n",
      " [10  0]\n",
      " [12  0]\n",
      " [14  1]\n",
      " [16  1]\n",
      " [18  1]\n",
      " [20  1]]\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "x_data = np.arange(1,11).reshape(10,1) * 2\n",
    "t_data = np.array([0,0,0,0,0,0,1,1,1,1]).reshape(10,1)\n",
    "print(np.concatenate((x_data, t_data), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42a3d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL W =  [[0.50910612]]  b =  [0.91183876]\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1,)\n",
    "print(\"INITIAL W = \", W, \" b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7d03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9f9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x_data, t_data):\n",
    "    delta = 1e-7 # prevent log 0 case\n",
    "    z = np.dot(x_data, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return -np.sum(np.log(y + delta) * t_data + np.log(1-y + delta) * (1-t_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aeedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x : loss_func(x_data, t_data)\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa10ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0:  W =  [[0.09573972]]  b =  [0.86534392] error =  10.754347739792678\n",
      "STEP 400:  W =  [[0.43549611]]  b =  [-4.08204201] error =  3.2484120905811564\n",
      "STEP 800:  W =  [[0.45206595]]  b =  [-5.62376887] error =  1.7888346804155144\n",
      "STEP 1200:  W =  [[0.52972106]]  b =  [-6.6578429] error =  1.5208528807512594\n",
      "STEP 1600:  W =  [[0.59115561]]  b =  [-7.47367601] error =  1.3543932334883169\n",
      "STEP 2000:  W =  [[0.64278699]]  b =  [-8.15782216] error =  1.237401448290138\n",
      "STEP 2400:  W =  [[0.68777084]]  b =  [-8.75282306] error =  1.1489218656337417\n",
      "STEP 2800:  W =  [[0.72790973]]  b =  [-9.2829583] error =  1.0786788359758073\n",
      "STEP 3200:  W =  [[0.76433802]]  b =  [-9.7634905] error =  1.0209590938113053\n",
      "STEP 3600:  W =  [[0.79781973]]  b =  [-10.20468831] error =  0.9722953733144631\n",
      "STEP 4000:  W =  [[0.82889612]]  b =  [-10.61381788] error =  0.930442834174251\n",
      "STEP 4400:  W =  [[0.85796584]]  b =  [-10.99622531] error =  0.8938738407100553\n",
      "STEP 4800:  W =  [[0.88533178]]  b =  [-11.35596806] error =  0.8615068534333227\n",
      "STEP 5200:  W =  [[0.91122995]]  b =  [-11.69620468] error =  0.8325510921066538\n",
      "STEP 5600:  W =  [[0.93584815]]  b =  [-12.01944629] error =  0.8064126989639028\n",
      "STEP 6000:  W =  [[0.95933852]]  b =  [-12.32772512] error =  0.7826355265696129\n",
      "STEP 6400:  W =  [[0.98182616]]  b =  [-12.62271116] error =  0.7608623811853577\n",
      "STEP 6800:  W =  [[1.00341534]]  b =  [-12.90579488] error =  0.7408088516436475\n",
      "STEP 7200:  W =  [[1.02419393]]  b =  [-13.17814753] error =  0.7222451552236538\n",
      "STEP 7600:  W =  [[1.04423677]]  b =  [-13.44076571] error =  0.7049832461604264\n",
      "STEP 8000:  W =  [[1.06360814]]  b =  [-13.69450518] error =  0.6888674706680727\n",
      "STEP 8400:  W =  [[1.08236375]]  b =  [-13.94010672] error =  0.6737676679810223\n",
      "STEP 8800:  W =  [[1.10055218]]  b =  [-14.17821624] error =  0.6595739934871226\n",
      "STEP 9200:  W =  [[1.1182161]]  b =  [-14.40940067] error =  0.6461929768118537\n",
      "STEP 9600:  W =  [[1.1353932]]  b =  [-14.63416061] error =  0.6335444803122287\n",
      "STEP 10000:  W =  [[1.15211698]]  b =  [-14.8529405] error =  0.621559323983283\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    W -= learning_rate * multi_var_numerical_derivative(f, W)\n",
    "    b -= learning_rate * multi_var_numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"STEP %d: \" % step, \"W = \", W, \" b = \", b, \"error = \", loss_func(x_data, t_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df8fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return y, 1 if y > 0.5 else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d252fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.86445033]]), 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(14.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1753eeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.38900935]]), 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(12.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536ac20",
   "metadata": {},
   "source": [
    "#### two variable logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "705d163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  0]\n",
      " [ 4 11  0]\n",
      " [ 6  6  0]\n",
      " [ 8  5  0]\n",
      " [10  7  1]\n",
      " [12 16  1]\n",
      " [14  8  1]\n",
      " [16  3  1]\n",
      " [18  7  1]]\n"
     ]
    }
   ],
   "source": [
    "x1_data = np.array([2,4,6,8,10,12,14,16,18]).reshape(-1,1)\n",
    "x2_data = np.array([4,11,6,5,7,16,8,3,7]).reshape(-1,1)\n",
    "x_data = np.concatenate((x1_data, x2_data), axis=1)\n",
    "t_data = np.array([0,0,0,0,1,1,1,1,1]).reshape(-1,1)\n",
    "\n",
    "print(np.concatenate((x_data, t_data), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e401f21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL W =  [[0.42002643]\n",
      " [0.24167481]]  b =  [0.26950333]\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(2,1)\n",
    "b = np.random.rand(1,)\n",
    "\n",
    "print(\"INITIAL W = \", W, \" b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aabe030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x_data, t_data):\n",
    "    delta = 1e-7\n",
    "    z = np.dot(x_data,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return -np.sum( t_data*np.log(y) + (1-t_data) * np.log(1-y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "470f9ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: W =  [[ 0.22448169]\n",
      " [-0.01132964]]  b =  [0.24051661]  error =  6.437644281185769\n",
      "STEP 5000: W =  [[1.03686167]\n",
      " [0.16110184]]  b =  [-10.20795907]  error =  0.6037086217551586\n",
      "STEP 10000: W =  [[1.28112949]\n",
      " [0.31313454]]  b =  [-13.33308819]  error =  0.40394944011309436\n",
      "STEP 15000: W =  [[1.44080933]\n",
      " [0.43875227]]  b =  [-15.52368764]  error =  0.30679452337789587\n",
      "STEP 20000: W =  [[1.56582054]\n",
      " [0.53767763]]  b =  [-17.24080536]  error =  0.24722609395858894\n",
      "STEP 25000: W =  [[1.66963914]\n",
      " [0.61795755]]  b =  [-18.65538367]  error =  0.20683474214903344\n",
      "STEP 30000: W =  [[1.7585193 ]\n",
      " [0.68525682]]  b =  [-19.85786173]  error =  0.17766104931404325\n",
      "STEP 35000: W =  [[1.83620328]\n",
      " [0.74311705]]  b =  [-20.90315144]  error =  0.15562171964895286\n",
      "STEP 40000: W =  [[1.90517113]\n",
      " [0.79383055]]  b =  [-21.82728648]  error =  0.1383979183004886\n",
      "STEP 45000: W =  [[1.96716189]\n",
      " [0.838953  ]]  b =  [-22.65521575]  error =  0.124574878349312\n",
      "STEP 50000: W =  [[2.02344366]\n",
      " [0.87958518]]  b =  [-23.4049284]  error =  0.11324092695003567\n",
      "STEP 55000: W =  [[2.07496953]\n",
      " [0.9165335 ]]  b =  [-24.08981924]  error =  0.1037825035073767\n",
      "STEP 60000: W =  [[2.12247372]\n",
      " [0.95040591]]  b =  [-24.72012751]  error =  0.09577176089214887\n",
      "STEP 65000: W =  [[2.16653355]\n",
      " [0.98167192]]  b =  [-25.30385374]  error =  0.08890139172356651\n",
      "STEP 70000: W =  [[2.20761103]\n",
      " [1.01070155]]  b =  [-25.84736645]  error =  0.08294506179626132\n",
      "STEP 75000: W =  [[2.24608153]\n",
      " [1.03779149]]  b =  [-26.35581666]  error =  0.07773244492342585\n",
      "STEP 80000: W =  [[2.28225409]\n",
      " [1.06318327]]  b =  [-26.83342893]  error =  0.07313294361885672\n"
     ]
    }
   ],
   "source": [
    "f = lambda x : loss_func(x_data, t_data)\n",
    "learning_rate = 1e-2\n",
    "\n",
    "for step in range(80001):\n",
    "    W -= learning_rate * multi_var_numerical_derivative(f, W)\n",
    "    b -= learning_rate * multi_var_numerical_derivative(f, b) \n",
    "    \n",
    "    if (step % 5000 == 0):\n",
    "        print(\"STEP %d: W = \" % step, W, \" b = \", b, \" error = \", loss_func(x_data, t_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc0978ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[4.08222636e-05]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(predict(np.array([5,5]).reshape(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4955ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.00706008]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(predict(np.array([4,12]).reshape(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e332502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.99998955]]), 1)\n"
     ]
    }
   ],
   "source": [
    "print(predict(np.array([7,21]).reshape(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890aa4f",
   "metadata": {},
   "source": [
    "W1 = 2.28, W2 = 1.06이므로 X1의 가중치가 더 크다고 해석할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42fb84",
   "metadata": {},
   "source": [
    "#### Logic gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad02577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, name, x_data, t_data):\n",
    "        self.name = name\n",
    "        self.__x_data = x_data.reshape(4,2)\n",
    "        self.__t_data = t_data.reshape(4,1)\n",
    "        \n",
    "        # Input layer (1), Output layer (2)의 Single layer perceptron 구성\n",
    "        self.__W = np.random.rand(2,1)\n",
    "        self.__b = np.random.rand(1,)\n",
    "        \n",
    "        self.__learning_rate = 1e-2\n",
    "        \n",
    "    def __loss_func(self):\n",
    "        delta = 1e-7\n",
    "        z = np.dot(self.__x_data, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        return -np.sum( np.log(y+delta)*self.__t_data + np.log(1-y+delta)*(1-self.__t_data) )\n",
    "    \n",
    "    def error_val(self):\n",
    "        return self.__loss_func()\n",
    "    \n",
    "    def train(self):\n",
    "        f = lambda x : self.__loss_func()\n",
    "        \n",
    "        for step in range(10001):\n",
    "            self.__W -= self.__learning_rate * multi_var_numerical_derivative(f, self.__W)\n",
    "            self.__b -= self.__learning_rate * multi_var_numerical_derivative(f, self.__b)\n",
    "            \n",
    "            if (step % 400 == 0):\n",
    "                print(\"STEP %d: W = \" % step, self.__W, \" b = \", self.__b, \" error = \", self.error_val())  \n",
    "                \n",
    "    def predict(self, x): # x.shape = (1,2)\n",
    "        z = np.dot(x, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        return y, 1 if y > 0.5 else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3592530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inputs\n",
    "test_input = np.array([ [0,0], [0,1], [1,0], [1,1] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b050efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND Gate\n",
    "x_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "t_data = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "AND_obj = LogicGate(\"AND\", x_data, t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61f59790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: W =  [[0.87208683]\n",
      " [0.59753159]]  b =  [0.59312099]  error =  4.281868735604514\n",
      "STEP 400: W =  [[1.01990169]\n",
      " [0.90774262]]  b =  [-1.83924367]  error =  1.4947205610236511\n",
      "STEP 800: W =  [[1.61018638]\n",
      " [1.55927475]]  b =  [-2.68541182]  error =  1.120548788743588\n",
      "STEP 1200: W =  [[2.06203636]\n",
      " [2.03707822]]  b =  [-3.34060432]  error =  0.9048425434351018\n",
      "STEP 1600: W =  [[2.43192223]\n",
      " [2.41882594]]  b =  [-3.88098514]  error =  0.7612291617146405\n",
      "STEP 2000: W =  [[2.74675503]\n",
      " [2.73946704]]  b =  [-4.34294322]  error =  0.6574747879362854\n",
      "STEP 2400: W =  [[3.02144707]\n",
      " [3.0171812 ]]  b =  [-4.74726492]  error =  0.5785410914484456\n",
      "STEP 2800: W =  [[3.26531478]\n",
      " [3.26270679]]  b =  [-5.10709513]  error =  0.5163033059508144\n",
      "STEP 3200: W =  [[3.48465441]\n",
      " [3.48299876]]  b =  [-5.43137328]  error =  0.465913398191822\n",
      "STEP 3600: W =  [[3.6839594 ]\n",
      " [3.68287327]]  b =  [-5.72650837]  error =  0.42426781355445686\n",
      "STEP 4000: W =  [[3.86656719]\n",
      " [3.86583388]]  b =  [-5.99727995]  error =  0.3892737694326347\n",
      "STEP 4400: W =  [[4.03503354]\n",
      " [4.03452574]]  b =  [-6.24736201]  error =  0.35946259830690297\n",
      "STEP 4800: W =  [[4.19136371]\n",
      " [4.19100407]]  b =  [-6.4796472]  error =  0.3337704512373736\n",
      "STEP 5200: W =  [[4.33716238]\n",
      " [4.33690251]]  b =  [-6.6964578]  error =  0.31140654439376725\n",
      "STEP 5600: W =  [[4.47373504]\n",
      " [4.47354386]]  b =  [-6.89968854]  error =  0.2917702598779552\n",
      "STEP 6000: W =  [[4.6021587 ]\n",
      " [4.60201575]]  b =  [-7.09090662]  error =  0.27439697794579876\n",
      "STEP 6400: W =  [[4.72333265]\n",
      " [4.72322419]]  b =  [-7.27142366]  error =  0.2589215518036441\n",
      "STEP 6800: W =  [[4.83801571]\n",
      " [4.83793231]]  b =  [-7.44234869]  error =  0.24505301409998512\n",
      "STEP 7200: W =  [[4.94685413]\n",
      " [4.94678923]]  b =  [-7.60462794]  error =  0.2325566560929352\n",
      "STEP 7600: W =  [[5.05040287]\n",
      " [5.05035179]]  b =  [-7.75907528]  error =  0.22124107535985593\n",
      "STEP 8000: W =  [[5.14914196]\n",
      " [5.14910135]]  b =  [-7.90639578]  error =  0.2109486493214195\n",
      "STEP 8400: W =  [[5.24348947]\n",
      " [5.24345688]]  b =  [-8.04720426]  error =  0.20154841879709223\n",
      "STEP 8800: W =  [[5.33381168]\n",
      " [5.3337853 ]]  b =  [-8.18204002]  error =  0.19293069746559546\n",
      "STEP 9200: W =  [[5.42043127]\n",
      " [5.42040974]]  b =  [-8.31137867]  error =  0.1850029371429393\n",
      "STEP 9600: W =  [[5.50363397]\n",
      " [5.50361627]]  b =  [-8.43564177]  error =  0.17768652002622404\n",
      "STEP 10000: W =  [[5.58367397]\n",
      " [5.58365932]]  b =  [-8.55520466]  error =  0.17091424411636738\n"
     ]
    }
   ],
   "source": [
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bfcf042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.0001925]), 0)\n",
      "(array([0.04872804]), 0)\n",
      "(array([0.04872872]), 0)\n",
      "(array([0.93163809]), 1)\n"
     ]
    }
   ],
   "source": [
    "for e in test_input:\n",
    "    print(AND_obj.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e707e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR Gate\n",
    "x_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "t_data = np.array([[0], [1], [1], [1]])\n",
    "\n",
    "OR_obj = LogicGate(\"OR\", x_data, t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2abd08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: W =  [[0.98222914]\n",
      " [0.91685623]]  b =  [0.6998722]  error =  1.5264987216378842\n",
      "STEP 400: W =  [[1.80387999]\n",
      " [1.76584864]]  b =  [-0.08297545]  error =  1.017696673120925\n",
      "STEP 800: W =  [[2.44694267]\n",
      " [2.42362125]]  b =  [-0.54114921]  error =  0.7521481258613677\n",
      "STEP 1200: W =  [[2.96044195]\n",
      " [2.94516269]]  b =  [-0.86396857]  error =  0.591638074362282\n",
      "STEP 1600: W =  [[3.38440061]\n",
      " [3.37380186]]  b =  [-1.11350346]  error =  0.48497146569313065\n",
      "STEP 2000: W =  [[3.74382996]\n",
      " [3.736129  ]]  b =  [-1.31701803]  error =  0.40938530088011316\n",
      "STEP 2400: W =  [[4.05487992]\n",
      " [4.04907146]]  b =  [-1.48882116]  error =  0.3532736526513505\n",
      "STEP 2800: W =  [[4.32847383]\n",
      " [4.32395787]]  b =  [-1.63738757]  error =  0.31011648076458725\n",
      "STEP 3200: W =  [[4.5723025 ]\n",
      " [4.56870282]]  b =  [-1.76817549]  error =  0.2759808396790418\n",
      "STEP 3600: W =  [[4.79196425]\n",
      " [4.78903481]]  b =  [-1.88491816]  error =  0.24836104827117822\n",
      "STEP 4000: W =  [[4.99164904]\n",
      " [4.98922303]]  b =  [-1.99028606]  error =  0.2255896068415261\n",
      "STEP 4400: W =  [[5.17456726]\n",
      " [5.17252805]]  b =  [-2.08625711]  error =  0.2065164352260699\n",
      "STEP 4800: W =  [[5.3432286 ]\n",
      " [5.34149244]]  b =  [-2.1743375]  error =  0.1903242247709412\n",
      "STEP 5200: W =  [[5.49962933]\n",
      " [5.49813464]]  b =  [-2.25570072]  error =  0.17641717265898801\n",
      "STEP 5600: W =  [[5.64538151]\n",
      " [5.64408212]]  b =  [-2.33127869]  error =  0.16435130981659432\n",
      "STEP 6000: W =  [[5.78180439]\n",
      " [5.78066503]]  b =  [-2.40182364]  error =  0.15378941787791478\n",
      "STEP 6400: W =  [[5.90999044]\n",
      " [5.90898376]]  b =  [-2.46795137]  error =  0.14447101555022504\n",
      "STEP 6800: W =  [[6.03085387]\n",
      " [6.02995832]]  b =  [-2.53017221]  error =  0.13619187327773385\n",
      "STEP 7200: W =  [[6.14516699]\n",
      " [6.14436541]]  b =  [-2.5889137]  error =  0.1287897199598299\n",
      "STEP 7600: W =  [[6.25358782]\n",
      " [6.25286637]]  b =  [-2.64453754]  error =  0.12213407245901174\n",
      "STEP 8000: W =  [[6.35668133]\n",
      " [6.35602873]]  b =  [-2.69735229]  error =  0.1161188702267088\n",
      "STEP 8400: W =  [[6.45493605]\n",
      " [6.45434302]]  b =  [-2.74762333]  error =  0.11065705600505259\n",
      "STEP 8800: W =  [[6.54877711]\n",
      " [6.54823595]]  b =  [-2.79558046]  error =  0.10567653058219624\n",
      "STEP 9200: W =  [[6.63857664]\n",
      " [6.63808092]]  b =  [-2.84142395]  error =  0.10111709333606411\n",
      "STEP 9600: W =  [[6.72466221]\n",
      " [6.7242065 ]]  b =  [-2.88532941]  error =  0.09692810039621647\n",
      "STEP 10000: W =  [[6.80732353]\n",
      " [6.80690323]]  b =  [-2.92745161]  error =  0.09306665222949842\n"
     ]
    }
   ],
   "source": [
    "OR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bf1ac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.0508131]), 0)\n",
      "(array([0.97975613]), 1)\n",
      "(array([0.97976446]), 1)\n",
      "(array([0.99997716]), 1)\n"
     ]
    }
   ],
   "source": [
    "for e in test_input:\n",
    "    print(OR_obj.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0ec1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAND Gate\n",
    "x_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "t_data = np.array([[1], [1], [1], [0]])\n",
    "\n",
    "NAND_obj = LogicGate(\"NAND\", x_data, t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06976ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: W =  [[0.70767673]\n",
      " [0.79239451]]  b =  [0.09663901]  error =  3.1412586848571085\n",
      "STEP 400: W =  [[-0.61714412]\n",
      " [-0.58202097]]  b =  [1.37947152]  error =  1.7666943185966524\n",
      "STEP 800: W =  [[-1.34652824]\n",
      " [-1.3311252 ]]  b =  [2.34687569]  error =  1.254954753355861\n",
      "STEP 1200: W =  [[-1.86383538]\n",
      " [-1.85652683]]  b =  [3.07154332]  error =  0.9870976611348585\n",
      "STEP 1600: W =  [[-2.27154743]\n",
      " [-2.26782039]]  b =  [3.65618738]  error =  0.817751070276657\n",
      "STEP 2000: W =  [[-2.61119029]\n",
      " [-2.6091666 ]]  b =  [4.14919948]  error =  0.6990852424060003\n",
      "STEP 2400: W =  [[-2.9035898 ]\n",
      " [-2.90243005]]  b =  [4.576745]  error =  0.6105939778349616\n",
      "STEP 2800: W =  [[-3.1608482 ]\n",
      " [-3.16015198]]  b =  [4.95471723]  error =  0.5418027986187952\n",
      "STEP 3200: W =  [[-3.39073686]\n",
      " [-3.3903018 ]]  b =  [5.29361702]  error =  0.4866987855603152\n",
      "STEP 3600: W =  [[-3.59860491]\n",
      " [-3.59832342]]  b =  [5.60081561]  error =  0.4415383876734241\n",
      "STEP 4000: W =  [[-3.78832329]\n",
      " [-3.78813553]]  b =  [5.88172343]  error =  0.40384941721910494\n",
      "STEP 4400: W =  [[-3.96279998]\n",
      " [-3.96267134]]  b =  [6.1404485]  error =  0.37192486424670423\n",
      "STEP 4800: W =  [[-4.1242836 ]\n",
      " [-4.12419335]]  b =  [6.38019358]  error =  0.34454419760379307\n",
      "STEP 5200: W =  [[-4.27455338]\n",
      " [-4.27448873]]  b =  [6.60350929]  error =  0.32080980623195543\n",
      "STEP 5600: W =  [[-4.41504379]\n",
      " [-4.41499659]]  b =  [6.81246275]  error =  0.3000460201141476\n",
      "STEP 6000: W =  [[-4.54692955]\n",
      " [-4.5468945 ]]  b =  [7.00875403]  error =  0.28173414997408924\n",
      "STEP 6400: W =  [[-4.67118554]\n",
      " [-4.67115911]]  b =  [7.19379892]  error =  0.26546925316039244\n",
      "STEP 6800: W =  [[-4.78863009]\n",
      " [-4.78860988]]  b =  [7.36878939]  error =  0.25093052507644253\n",
      "STEP 7200: W =  [[-4.89995702]\n",
      " [-4.89994137]]  b =  [7.53473858]  error =  0.23786052112059375\n",
      "STEP 7600: W =  [[-5.00575977]\n",
      " [-5.00574751]]  b =  [7.69251493]  error =  0.22605026441296783\n",
      "STEP 8000: W =  [[-5.10654995]\n",
      " [-5.10654024]]  b =  [7.8428685]  error =  0.21532837296213087\n",
      "STEP 8400: W =  [[-5.20277172]\n",
      " [-5.20276396]]  b =  [7.98645153]  error =  0.2055529906310919\n",
      "STEP 8800: W =  [[-5.29481316]\n",
      " [-5.2948069 ]]  b =  [8.12383468]  error =  0.196605710940841\n",
      "STEP 9200: W =  [[-5.3830153 ]\n",
      " [-5.38301022]]  b =  [8.25552012]  error =  0.18838694117170618\n",
      "STEP 9600: W =  [[-5.46767945]\n",
      " [-5.46767528]]  b =  [8.38195194]  error =  0.18081232315133358\n",
      "STEP 10000: W =  [[-5.54907308]\n",
      " [-5.54906964]]  b =  [8.50352481]  error =  0.17380993987140278\n"
     ]
    }
   ],
   "source": [
    "NAND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a29ec65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.99979729]), 1)\n",
      "(array([0.95047363]), 1)\n",
      "(array([0.95047347]), 1)\n",
      "(array([0.06948561]), 0)\n"
     ]
    }
   ],
   "source": [
    "for e in test_input:\n",
    "    print(NAND_obj.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "237c0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR Gate\n",
    "x_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "t_data = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "XOR_obj = LogicGate(\"XOR\", x_data, t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdc253ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: W =  [[0.42099033]\n",
      " [0.1181202 ]]  b =  [0.44308452]  error =  3.042386282249921\n",
      "STEP 400: W =  [[ 0.0586443]\n",
      " [-0.0538375]]  b =  [-0.00153638]  error =  2.773380397173542\n",
      "STEP 800: W =  [[ 0.02170245]\n",
      " [-0.01963026]]  b =  [-0.00122566]  error =  2.772694981182894\n",
      "STEP 1200: W =  [[ 0.00814452]\n",
      " [-0.00704214]]  b =  [-0.00065318]  error =  2.7726024180326947\n",
      "STEP 1600: W =  [[ 0.00308338]\n",
      " [-0.0024965 ]]  b =  [-0.00034774]  error =  2.772589891184546\n",
      "STEP 2000: W =  [[ 0.0011813 ]\n",
      " [-0.00086886]]  b =  [-0.00018513]  error =  2.7725881914554233\n",
      "STEP 2400: W =  [[ 0.0004598 ]\n",
      " [-0.00029347]]  b =  [-9.85564877e-05]  error =  2.7725879595507066\n",
      "STEP 2800: W =  [[ 1.82658451e-04]\n",
      " [-9.41065760e-05]]  b =  [-5.24689204e-05]  error =  2.7725879275509415\n",
      "STEP 3200: W =  [[ 7.44157629e-05]\n",
      " [-2.72730381e-05]]  b =  [-2.79330947e-05]  error =  2.772587923034564\n",
      "STEP 3600: W =  [[ 3.12299950e-05]\n",
      " [-6.13242923e-06]]  b =  [-1.4870856e-05]  error =  2.7725879223691727\n",
      "STEP 4000: W =  [[ 1.35444841e-05]\n",
      " [-1.83189904e-07]]  b =  [-7.91685887e-06]  error =  2.772587922263561\n",
      "STEP 4400: W =  [[6.07850924e-06]\n",
      " [1.03469720e-06]]  b =  [-4.21473031e-06]  error =  2.7725879222448304\n",
      "STEP 4800: W =  [[2.8200401e-06]\n",
      " [9.6684634e-07]]  b =  [-2.24381321e-06]  error =  2.772587922241034\n",
      "STEP 5200: W =  [[1.34846953e-06]\n",
      " [6.67570802e-07]]  b =  [-1.19454798e-06]  error =  2.772587922240162\n",
      "STEP 5600: W =  [[6.61731859e-07]\n",
      " [4.11556171e-07]]  b =  [-6.35946548e-07]  error =  2.7725879222399423\n",
      "STEP 6000: W =  [[3.31654805e-07]\n",
      " [2.39735324e-07]]  b =  [-3.38561232e-07]  error =  2.7725879222398837\n",
      "STEP 6400: W =  [[1.68983284e-07]\n",
      " [1.35210913e-07]]  b =  [-1.80241652e-07]  error =  2.7725879222398673\n",
      "STEP 6800: W =  [[8.71760343e-08]\n",
      " [7.47682175e-08]]  b =  [-9.59557405e-08]  error =  2.7725879222398633\n",
      "STEP 7200: W =  [[4.53868844e-08]\n",
      " [4.08285442e-08]]  b =  [-5.1084678e-08]  error =  2.7725879222398615\n",
      "STEP 7600: W =  [[2.37862298e-08]\n",
      " [2.21115829e-08]]  b =  [-2.71956317e-08]  error =  2.772587922239862\n",
      "STEP 8000: W =  [[1.25246603e-08]\n",
      " [1.19101432e-08]]  b =  [-1.44784933e-08]  error =  2.772587922239862\n",
      "STEP 8400: W =  [[6.61667510e-09]\n",
      " [6.39175746e-09]]  b =  [-7.70804243e-09]  error =  2.772587922239862\n",
      "STEP 8800: W =  [[3.50358753e-09]\n",
      " [3.42186646e-09]]  b =  [-4.1038144e-09]  error =  2.772587922239862\n",
      "STEP 9200: W =  [[1.85799276e-09]\n",
      " [1.82876303e-09]]  b =  [-2.18470508e-09]  error =  2.772587922239862\n",
      "STEP 9600: W =  [[9.86356663e-10]\n",
      " [9.76222769e-10]]  b =  [-1.16336651e-09]  error =  2.772587922239862\n",
      "STEP 10000: W =  [[5.24082000e-10]\n",
      " [5.21031329e-10]]  b =  [-6.19268414e-10]  error =  2.772587922239862\n"
     ]
    }
   ],
   "source": [
    "XOR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "778dd09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.5]), 0)\n",
      "(array([0.5]), 0)\n",
      "(array([0.5]), 0)\n",
      "(array([0.5]), 1)\n"
     ]
    }
   ],
   "source": [
    "for e in test_input:\n",
    "    print(XOR_obj.predict(e)) # XOR not working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654f553",
   "metadata": {},
   "source": [
    "#### XOR\n",
    "- logistic regression으로 만든 XOR classification이 제대로 동작 X\n",
    "- XOR = AND(NAND, OR) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e0d0fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  [0 0] NAND out =  1  OR out =  0 XOR out =  0\n",
      "Input =  [0 1] NAND out =  1  OR out =  1 XOR out =  1\n",
      "Input =  [1 0] NAND out =  1  OR out =  1 XOR out =  1\n",
      "Input =  [1 1] NAND out =  0  OR out =  1 XOR out =  0\n"
     ]
    }
   ],
   "source": [
    "for e in test_input:\n",
    "    NAND_out = NAND_obj.predict(e)[-1]\n",
    "    OR_out = OR_obj.predict(e)[-1]\n",
    "    \n",
    "    new_input = np.array([NAND_out, OR_out])\n",
    "    res = AND_obj.predict(new_input)\n",
    "\n",
    "    print(\"Input = \", e, \"NAND out = \", NAND_out, \" OR out = \", OR_out, \"XOR out = \", res[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
